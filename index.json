[{"content":"","date":"22 February 2026","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":" Email Dashboard is Live (And My Inbox Has No Excuses Now) # Part 2 of the Unread Mail Dashboard series â€” the sync works, the UI is done, and I now know exactly how behind I am.\nIf you missed Part 1, I\u0026rsquo;d recommend reading it first â€” it covers how I set up the Google Apps Script backend and why I started this project in the first place. The short version: I had 500+ unread emails, no visibility into my inbox habits, and I wanted an excuse to build something real with Streamlit.\nThis post covers everything that came after â€” the completed Streamlit frontend, the final GScript sync logic, and what the app actually tells you once it\u0026rsquo;s running.\nWhat the App Actually Does (Full Picture) # The app is a personal email productivity dashboard that connects to your Gmail â€” not through the Gmail API directly, but through a Google Sheet that acts as the database, kept up to date by a Google Apps Script that syncs on a schedule.\nHere\u0026rsquo;s the full flow:\nGoogle Apps Script runs on a trigger at the end of every day (more on triggers below). When it runs, it does three things in sequence:\nMarks emails as read. It fetches all currently unread threads from Gmail and compares them against your sheet. Any email that was previously logged as unread but is no longer in the unread list gets its \u0026ldquo;Read Date\u0026rdquo; column updated to today\u0026rsquo;s date.\nCleans up deleted/trashed emails. For every logged thread, it checks if Gmail still has it. If the thread is in trash or has been permanently deleted, that row gets removed from the sheet. The database stays accurate.\nAppends new emails. It searches Gmail for threads newer than the last logged entry and adds any it hasn\u0026rsquo;t seen before â€” capturing the Thread ID, subject, date, a direct link to the email, and whether it was already read at the time of logging.\nThe Google Sheet (Sheet2) is the single source of truth. It has six columns: Thread ID, message date, subject, link, a checkbox for read status, and the read date. The checkbox is a real GSheets checkbox â€” so you can also manually tick it if needed.\nThe Streamlit app reads from that sheet via streamlit-gsheets and gives you:\nA date range picker to slice any time window you care about A headline stat â€” \u0026ldquo;In X days, you received Y emails and read Z emails\u0026rdquo; â€” which updates dynamically with the selected range Four key metrics: Total unread â€” your current backlog across all time Received per day â€” average inflow in the selected window Read per day â€” average throughput in the selected window Days to finish â€” backlog Ã· read rate. The number you don\u0026rsquo;t want to look at but can\u0026rsquo;t stop looking at. A side-by-side bar chart showing daily received vs read counts, so you can see at a glance whether you\u0026rsquo;re keeping up or falling further behind A \u0026ldquo;Sync Emails Now\u0026rdquo; button that manually triggers the GScript and shows you exactly what changed: how many new emails were added, how many got marked read, how many were removed Google sheet used as database Auth: Keeping It Private # Since this is personal email data, the app is gated behind Google login. Streamlit recently shipped st.user which makes this almost embarrassingly easy:\nif not st.user.is_logged_in: st.button(\u0026#34;Log in with Google\u0026#34;, on_click=st.login) st.stop() if st.user.email not in ALLOWED_EMAILS: st.error(\u0026#34;Access denied.\u0026#34;) st.stop() That\u0026rsquo;s the entire auth layer. An allowlist of approved emails, three if blocks, done. No tokens to manage, no OAuth dance to implement yourself.\nThe Automated Trigger # One thing I didn\u0026rsquo;t want was to manually run the script every time. GAS has built-in time-based triggers â€” I set one to fire at the end of each day (11 PMâ€“midnight). That means by the time I open the dashboard in the morning, it already reflects everything from the previous day.\nTo set this up: in your Apps Script project, go to Triggers â†’ Add Trigger, set the function to syncAndLogThreads, event source to Time-driven, and pick Day timer with your preferred window.\nTechnical Bits Worth Noting # The sync window buffer. The script searches Gmail with an after: Unix timestamp filter based on the last logged entry. I subtract 86400 seconds (one day) as a safety buffer â€” it re-checks the last day\u0026rsquo;s worth of emails on every run to make sure nothing slips through. Slightly redundant but never misses anything.\nDelete detection via try/catch. The cleanest solution I found: wrap getThreadById() in a try/catch. If Gmail throws, the thread is permanently gone â€” drop the row. If it returns but isInTrash() is true â€” drop the row. Otherwise, keep it.\nBar chart x-axis gaps. st.bar_chart was showing hourly gaps between bars because it treated the date column as a true datetime. Fixing it was one line â€” convert to string before charting with dt.strftime('%Y-%m-%d') and the gaps disappear.\nPandas date types. The sheet stores dates as strings. After pd.to_datetime().dt.date, you get datetime.date objects â€” which compare fine with the date range picker output once you\u0026rsquo;re consistent about it. It\u0026rsquo;s not a hard problem but it\u0026rsquo;ll burn an hour if you\u0026rsquo;re not looking for it.\nThe Stack (Still $0) # Layer Tool Database Google Sheets Sync Logic Google Apps Script Frontend Streamlit Hosting Oracle Cloud Free Tier Dev Environment GitHub Codespaces Python dependencies: streamlit, streamlit-gsheets, pandas, requests, plotly\nThe Full Code # Google Apps Script (code.gs) # /** * SETTINGS */ const SYNC_LIMIT = 2000; const SEARCH_BATCH_SIZE = 100; const TIME_ZONE = \u0026#34;Asia/Kolkata\u0026#34;; function doGet() { const stats = syncAndLogThreads(); return ContentService.createTextOutput(JSON.stringify(stats)) .setMimeType(ContentService.MimeType.JSON); } function syncAndLogThreads() { const ss = SpreadsheetApp.getActiveSpreadsheet(); const now = new Date(); const todayStr = Utilities.formatDate(now, TIME_ZONE, \u0026#34;yyyy-MM-dd\u0026#34;); const nowFull = Utilities.formatDate(now, TIME_ZONE, \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); let targetSheet = ss.getSheetByName(\u0026#34;Sheet2\u0026#34;); let logSheet = ss.getSheetByName(\u0026#34;Sheet1\u0026#34;) || ss.insertSheet(\u0026#34;Sheet1\u0026#34;); const lastRow = targetSheet.getLastRow(); let stats = { newEmails: 0, markedRead: 0, deleted: 0, lastUpdated: nowFull }; if (lastRow \u0026lt;= 1) return stats; // 1. LOAD DATA console.log(\u0026#34;Step 1: Loading data...\u0026#34;); const startRow = Math.max(2, lastRow - SYNC_LIMIT + 1); const numRows = lastRow - startRow + 1; const range = targetSheet.getRange(startRow, 1, numRows, 6); let data = range.getValues(); // 2. BATCH SYNC STATUS \u0026amp; DELETE CHECK console.log(\u0026#34;Step 2: Syncing read/deleted status...\u0026#34;); const unreadThreads = GmailApp.search(\u0026#34;is:unread\u0026#34;, 0, 500); const unreadIds = new Set(unreadThreads.map(t =\u0026gt; t.getId())); let rowsToKeep = []; let sheetChanged = false; data.forEach((row) =\u0026gt; { const threadId = row[0]; const isMarkedReadInSheet = row[4]; let shouldDelete = false; if (threadId) { try { const thread = GmailApp.getThreadById(threadId); if (thread.isInTrash()) { shouldDelete = true; } else if (isMarkedReadInSheet === false \u0026amp;\u0026amp; !unreadIds.has(threadId)) { if (!thread.isUnread()) { row[4] = true; row[5] = todayStr; stats.markedRead++; sheetChanged = true; } } } catch(e) { shouldDelete = true; // Permanently deleted } } if (shouldDelete) { stats.deleted++; sheetChanged = true; } else { rowsToKeep.push(row); } }); if (sheetChanged) { range.clearContent(); if (rowsToKeep.length \u0026gt; 0) { targetSheet.getRange(startRow, 1, rowsToKeep.length, 6).setValues(rowsToKeep); } } // 3. LOG NEW EMAILS console.log(\u0026#34;Step 3: Checking for new emails...\u0026#34;); const lastEntry = rowsToKeep.length \u0026gt; 0 ? rowsToKeep[rowsToKeep.length - 1] : data[data.length - 1]; const lastEntryDateStr = lastEntry[1]; let lastLoggedDate = (lastEntryDateStr \u0026amp;\u0026amp; lastEntryDateStr !== \u0026#34;N/A\u0026#34;) ? new Date(lastEntryDateStr) : null; let searchQuery = \u0026#34;label:all\u0026#34;; if (lastLoggedDate) { const bufferTime = Math.floor(lastLoggedDate.getTime() / 1000) - 86400; searchQuery += ` after:${bufferTime}`; } const newThreads = GmailApp.search(searchQuery, 0, SEARCH_BATCH_SIZE); newThreads.reverse(); const existingIds = new Set(rowsToKeep.map(r =\u0026gt; r[0])); newThreads.forEach(thread =\u0026gt; { const threadId = thread.getId(); if (!existingIds.has(threadId)) { const msgDate = thread.getMessages()[0].getDate(); const formattedIST = Utilities.formatDate(msgDate, TIME_ZONE, \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;); const isRead = !thread.isUnread(); targetSheet.appendRow([ threadId, formattedIST, thread.getFirstMessageSubject(), `https://mail.google.com/mail/u/0/#inbox/${threadId}`, isRead, isRead ? todayStr : \u0026#34;\u0026#34; ]); targetSheet.getRange(targetSheet.getLastRow(), 5).insertCheckboxes(); stats.newEmails++; } }); logSheet.getRange(\u0026#34;A1\u0026#34;).setValue(nowFull); console.log(`Sync Complete: ${stats.newEmails} new, ${stats.markedRead} read, ${stats.deleted} deleted.`); return stats; } Streamlit App (app.py) # import streamlit as st import pandas as pd import requests import plotly.graph_objects as go from streamlit_gsheets import GSheetsConnection from datetime import date, timedelta # --- AUTH GATE --- if not st.user.is_logged_in: st.title(\u0026#34;ðŸ“§ Email Dashboard\u0026#34;) st.write(\u0026#34;Please log in to continue.\u0026#34;) st.button(\u0026#34;Log in with Google\u0026#34;, on_click=st.login) st.stop() # --- EMAIL ALLOWLIST --- ALLOWED_EMAILS = [\u0026#34;your-email@gmail.com\u0026#34;] # Replace with your email if st.user.email not in ALLOWED_EMAILS: st.error(f\u0026#34;Access denied. Your account ({st.user.email}) is not authorized to use this app.\u0026#34;) st.button(\u0026#34;Log out\u0026#34;, on_click=st.logout) st.stop() # --- ACTUAL APP STARTS HERE --- st.sidebar.write(f\u0026#34;Logged in as {st.user.email}\u0026#34;) st.sidebar.button(\u0026#34;Log out\u0026#34;, on_click=st.logout) API_URL = \u0026#34;YOUR_APPS_SCRIPT_DEPLOYMENT_URL\u0026#34; # Replace with your deployed GScript URL st.set_page_config(page_title=\u0026#34;Email Dashboard\u0026#34;, layout=\u0026#34;wide\u0026#34;) # --- Fetch Data --- conn = st.connection(\u0026#34;gsheets\u0026#34;, type=GSheetsConnection) df = conn.read(worksheet=\u0026#34;Sheet2\u0026#34;) # --- Data Cleaning --- df[\u0026#39;msg_date\u0026#39;] = pd.to_datetime(df[\u0026#39;msg_date\u0026#39;]).dt.date read_col_name = df.columns[-1] df[\u0026#39;Read date\u0026#39;] = pd.to_datetime(df[read_col_name], errors=\u0026#39;coerce\u0026#39;).dt.date total_rec_email_count = len(df) total_read_df = df[df[\u0026#39;Read date\u0026#39;].notnull()].copy() total_read_email_count = len(total_read_df) total_unread_email_count = total_rec_email_count - total_read_email_count st.sidebar.header(\u0026#34;Dashboard Controls\u0026#34;) min_date = df[\u0026#39;msg_date\u0026#39;].min() max_date = df[\u0026#39;msg_date\u0026#39;].max() user_selection = st.sidebar.date_input(\u0026#34;Select Date Range\u0026#34;, value=(date.today()-timedelta(days=6), date.today())) if st.sidebar.button(\u0026#39;Sync Emails Now\u0026#39;): with st.spinner(\u0026#39;Syncing with Gmail...\u0026#39;): try: response = requests.get(API_URL, allow_redirects=True) if response.status_code == 200: data = response.json() st.success(f\u0026#34;Sync Complete!\u0026#34;) col1, col2, col3 = st.columns(3) col1.metric(\u0026#34;New Emails\u0026#34;, data[\u0026#39;newEmails\u0026#39;]) col2.metric(\u0026#34;Marked Read\u0026#34;, data[\u0026#39;markedRead\u0026#39;]) col3.metric(\u0026#34;Removed (Deleted)\u0026#34;, data[\u0026#39;deleted\u0026#39;]) st.info(f\u0026#34;ðŸ•’ Last updated at: {data[\u0026#39;lastUpdated\u0026#39;]}\u0026#34;) st.cache_data.clear() st.cache_resource.clear() st.rerun() else: st.error(f\u0026#34;Server Error: {response.status_code}\u0026#34;) except Exception as e: st.error(f\u0026#34;Connection Error: {e}\u0026#34;) if st.sidebar.button(\u0026#34;clear cache\u0026#34;): st.cache_data.clear() st.cache_resource.clear() st.success(\u0026#34;cleared\u0026#34;) if st.sidebar.button(\u0026#34;rerun\u0026#34;): st.rerun() if len(user_selection) == 2: start_date, end_date = user_selection days_count = end_date - start_date + timedelta(days=1) days_count = days_count.days rec_mask = (df[\u0026#39;msg_date\u0026#39;] \u0026gt;= start_date) \u0026amp; (df[\u0026#39;msg_date\u0026#39;] \u0026lt;= end_date) rec_filtered_df = df.loc[rec_mask].copy() rec_emails_count = len(rec_filtered_df) rec_chart_data = rec_filtered_df.groupby(\u0026#39;msg_date\u0026#39;)[\u0026#39;Msg ID\u0026#39;].count().reset_index() rec_chart_data = rec_chart_data.rename(columns={\u0026#39;msg_date\u0026#39;: \u0026#39;Date\u0026#39;, \u0026#39;Msg ID\u0026#39;: \u0026#39;Received Count\u0026#39;}) read_mask = (df[\u0026#39;Read date\u0026#39;] \u0026gt;= start_date) \u0026amp; (df[\u0026#39;Read date\u0026#39;] \u0026lt;= end_date) read_filtered_df = df.loc[read_mask].copy() read_emails_count = len(read_filtered_df) read_chart_data = read_filtered_df.groupby(\u0026#39;Read date\u0026#39;)[\u0026#39;Msg ID\u0026#39;].count().reset_index() read_chart_data = read_chart_data.rename(columns={\u0026#39;Read date\u0026#39;: \u0026#39;Date\u0026#39;, \u0026#39;Msg ID\u0026#39;: \u0026#39;Read Count\u0026#39;}) # --- Final Data Preparation --- combined_df = pd.merge(rec_chart_data, read_chart_data, on=\u0026#39;Date\u0026#39;, how=\u0026#39;outer\u0026#39;) combined_df = combined_df.fillna(0).sort_values(\u0026#39;Date\u0026#39;) combined_df[\u0026#39;Date_Str\u0026#39;] = pd.to_datetime(combined_df[\u0026#39;Date\u0026#39;]).dt.strftime(\u0026#39;%Y-%m-%d\u0026#39;) st.title(f\u0026#34;In {days_count} days, you received {rec_emails_count} emails and read {read_emails_count} emails\u0026#34;) read_per_day = read_emails_count / days_count days_to_finish = total_unread_email_count / read_per_day m1, m2, m3, m4 = st.columns(4) m1.metric(\u0026#34;Total unread\u0026#34;, total_unread_email_count) m2.metric(\u0026#34;Received per day\u0026#34;, f\u0026#34;{rec_emails_count/days_count:.1f}\u0026#34;) m3.metric(\u0026#34;Read per day\u0026#34;, f\u0026#34;{read_per_day:.1f}\u0026#34;) m4.metric(\u0026#34;Days to finish\u0026#34;, f\u0026#34;{days_to_finish:.1f}\u0026#34;) st.subheader(\u0026#34;Daily Email Volume: Received vs Read\u0026#34;) st.bar_chart( combined_df, x=\u0026#34;Date_Str\u0026#34;, y=[\u0026#34;Received Count\u0026#34;, \u0026#34;Read Count\u0026#34;], color=[\u0026#34;#e82929\u0026#34;, \u0026#34;#1dad15\u0026#34;], stack=False ) else: st.info(\u0026#34;Please select a valid date range.\u0026#34;) What\u0026rsquo;s Next # The obvious next step is sender-level breakdowns â€” which domains are responsible for most of the clutter. The thread ID and subject are already in the sheet; I just need to add sender as a column in the GScript. That data would unlock a whole other layer of analysis: unsubscribe candidates, worst offenders by volume, read rate by sender.\nBut that\u0026rsquo;s a Part 3 problem.\nIf you\u0026rsquo;re building something similar or ran into any of the same issues, drop a comment. And if you want to go deeper on the initial data pipeline setup, Part 1 is here.\n","date":"22 February 2026","externalUrl":null,"permalink":"/posts/email-dashboard-is-live-and-my-inbox-has-no-excuses-now/","section":"Posts","summary":"Part 2 of the Unread Mail Dashboard series â€” the sync works, the UI is done, and I now know exactly how behind I am.","title":"Email Dashboard is Live (And My Inbox Has No Excuses Now)","type":"posts"},{"content":"","date":"22 February 2026","externalUrl":null,"permalink":"/categories/google-sheets/","section":"Categories","summary":"","title":"Google Sheets","type":"categories"},{"content":"","date":"22 February 2026","externalUrl":null,"permalink":"/categories/google-apps-script/","section":"Categories","summary":"","title":"Google-Apps-Script","type":"categories"},{"content":" ","date":"22 February 2026","externalUrl":null,"permalink":"/","section":"Hi, I'm Aayusha","summary":"","title":"Hi, I'm Aayusha","type":"page"},{"content":"","date":"22 February 2026","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"22 February 2026","externalUrl":null,"permalink":"/categories/streamlit/","section":"Categories","summary":"","title":"Streamlit","type":"categories"},{"content":" From Inbox Chaos to Data Science # Weâ€™ve all been there: signing up for a service \u0026ldquo;just to try it\u0026rdquo; and suddenly finding our inbox buried under a mountain of newsletters and automated alerts. I decided to stop complaining and start visualizing.\nThe goal for this dashboard was simple:\nDaily Volume: How many new emails actually hit my inbox every day? Subscription Audit: Am I oversubscribed to junk? (Spoiler: Yes). Read Velocity: How many emails am I actually opening versus letting sit? The \u0026ldquo;Meta\u0026rdquo; Reason # If Iâ€™m being honest, the real reason for this project wasn\u0026rsquo;t just about email managementâ€”it was an excuse to finally dive into Streamlit and build a live dashboard using real-world data that updates itself. Gmail is the perfect \u0026ldquo;living\u0026rdquo; database for this.\nPart 1: The Data Pipeline (GAS \u0026amp; Gmail) # Date: February 11, 2026\nI started by using a Google Sheet as my backend, powered by Google Apps Script (GAS). However, fetching the data wasn\u0026rsquo;t as straightforward as I expected.\nThe Technical Hurdles # The 500 Limit: Gmail\u0026rsquo;s API limits you to 500 emails per fetch. Since I had a massive backlog, I had to be strategic about how I pulled them. The Timezone Nightmare: Initially, my script\u0026rsquo;s count didn\u0026rsquo;t match the actual Gmail count. I discovered that GAS was pulling the PST server time from the metadata, which didn\u0026rsquo;t align with my local time. Regex to the Rescue: The \u0026ldquo;actual\u0026rdquo; time we see in our inbox is buried in the email body. I tried using LLMs to write a regex to extract this, but it took a few tries (and a fresh chat context) to get a script that accurately parsed the time string. The Logging Logic # To keep the sheet clean and avoid duplicates on re-runs, the script now:\nLogs a Unique Thread ID. Captures the Subject Line and a direct Email Link. Checks for existing IDs to skip already-logged mail. The Feedback Loop: I extended the code to check if an email previously logged as \u0026ldquo;unread\u0026rdquo; has now been opened. If it has, the script checks a box and logs the current date as the \u0026ldquo;Read Date.\u0026rdquo; Part 2: The Infrastructure (The \u0026ldquo;Free\u0026rdquo; Stack) # Date: February 12, 2026\nIâ€™m a big fan of high-performance setups with a $0 price tag. For this project, I leaned into the \u0026ldquo;Forever Free\u0026rdquo; ecosystem.\nComponent Service Used Database Google Sheets (via Apps Script) Hosting Oracle Cloud (Free Tier Perpetual Instance) IDE/Dev Env GitHub Codespaces Frontend Streamlit By linking GitHub Codespaces to my repository, I can now develop and tweak the dashboard from any browserâ€”whether I\u0026rsquo;m on my laptop or just checking in remotely.\nWhatâ€™s Next? # Now that the data pipeline is solid, Iâ€™m focused on the Streamlit UI. I want to build out specific \u0026ldquo;clutter\u0026rdquo; metrics to identify which senders are the worst offenders in my inbox. Stay tuned for the visual breakdown!.\n","date":"12 February 2026","externalUrl":null,"permalink":"/posts/unread-email-dashboard-uding-gsheet-and-streamlit/","section":"Posts","summary":"i have got lot of emails pending on gmail and i want to know how many emails are coming every day and how many i am reading","title":"Unread mail dashboard using gscript and streamlit","type":"posts"},{"content":" Generate QR Codes in Google Sheets Using External URLs # Iâ€™ll show how to generate QR codes directly inside Google Sheets using external URLs. This method does not require Google Apps Script, add-ons, or any complex setup.\nIt is quick, practical, and works well for most basic use cases.\nBasic QR Code Formula # Google Sheets supports the IMAGE() function, which allows images to be rendered inside cells.\n=IMAGE( \u0026#34;https://api.qrserver.com/v1/create-qr-code/?size=200x200\u0026amp;data=\u0026#34; \u0026amp; ENCODEURL(A1) ) How it works # A1 contains the text or URL ENCODEURL() safely handles special characters The external service generates the QR image IMAGE() displays it directly in the cell Whenever the value in A1 changes, the QR code updates automatically.\nAlternate QR Code URLs You Can Use # 1. QRServer (Recommended) # https://api.qrserver.com/v1/create-qr-code/?size=200x200\u0026amp;data= Example:\n=IMAGE(\u0026#34;https://api.qrserver.com/v1/create-qr-code/?size=200x200\u0026amp;data=\u0026#34; \u0026amp; ENCODEURL(A1)) Pros\nFree No API key required Stable and widely used 2. QuickChart # https://quickchart.io/qr?size=200\u0026amp;text= Example:\n=IMAGE(\u0026#34;https://quickchart.io/qr?size=200\u0026amp;text=\u0026#34; \u0026amp; ENCODEURL(A1)) Pros\nActively maintained Clean QR output 3. Image-Charts # https://image-charts.com/chart?chs=150x150\u0026amp;cht=qr\u0026amp;chl= Example:\n=IMAGE(\u0026#34;https://image-charts.com/chart?chs=150x150\u0026amp;cht=qr\u0026amp;chl=\u0026#34; \u0026amp; ENCODEURL(A1)) Pros\nActively maintained Works with Google Sheets IMAGE() function Simple URL-based integration When This Approach Makes Sense # This method is ideal when:\nYou want instant QR codes You are already working in Google Sheets You need bulk QR generation You want zero scripting Closing Note # This is one of the simplest ways to generate QR codes using Google Sheets.\nIn future posts, this can be extended using Google Apps Script for automation and advanced workflows.\n","date":"5 January 2026","externalUrl":null,"permalink":"/posts/qr-generator/","section":"Posts","summary":"A beginner-friendly guide to creating QR codes in Google Sheets using external QR APIs. Simple formulas, alternate services, and zero scripting.","title":"Generate QR Codes in Google Sheets","type":"posts"},{"content":"This site is a personal knowledge space.\nI work at the intersection of product, engineering, and automation. Over time, Iâ€™ve accumulated notes, mental models, small learnings, and practical decisions that usually stay scattered across notebooks, chats, or half-written docs.\nThis site is an attempt to make that thinking explicit.\nYouâ€™ll find:\nPractical notes from real work Experiments with tooling, automation, and systems Clarified thoughts on product and engineering decisions You wonâ€™t find:\nPolished tutorials written for SEO Motivational content Marketing-heavy writing Posts here may start rough and evolve over time. Thatâ€™s intentional.\n","date":"19 December 2025","externalUrl":null,"permalink":"/posts/not-my-post/","section":"Posts","summary":"What I plan to document here, and why this site exists in the first place.","title":"My POST","type":"posts"},{"content":"","date":"19 December 2025","externalUrl":null,"permalink":"/categories/samsung/","section":"Categories","summary":"","title":"Samsung","type":"categories"},{"content":" Hi, Iâ€™m Aayush # I write about technology, systems, and intentional simplicity.\nWhat I do # Automation \u0026amp; tooling Product \u0026amp; tech leadership Long-term thinking Elsewhere # GitHub LinkedIn Email ","externalUrl":null,"permalink":"/about/","section":"Hi, I'm Aayusha","summary":"","title":"About","type":"page"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]